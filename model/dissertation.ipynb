{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import the nhanes data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "plt.style.use('seaborn-white')\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "from sklearn import metrics\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "# from sklearn.cross_validation import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 12020\n",
      "Test set size: 3005\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('data_train.csv')\n",
    "df_test = pd.read_csv('data_test.csv')\n",
    "\n",
    "\n",
    "print('Training set size:', df_train.shape[0])\n",
    "print('Test set size:', df_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEQN</th>\n",
       "      <th>RIDAGEYR</th>\n",
       "      <th>RIAGENDR</th>\n",
       "      <th>RIDRETH1</th>\n",
       "      <th>BPXSY1</th>\n",
       "      <th>BMXBMI</th>\n",
       "      <th>SMQ020</th>\n",
       "      <th>LBXTC</th>\n",
       "      <th>PAD615</th>\n",
       "      <th>ALQ101</th>\n",
       "      <th>DIQ010</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47698.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>27.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68073.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77090.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>29.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>43558.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>24.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59274.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12015</th>\n",
       "      <td>77674.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>22.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12016</th>\n",
       "      <td>74600.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>35.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12017</th>\n",
       "      <td>66287.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>24.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12018</th>\n",
       "      <td>76281.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12019</th>\n",
       "      <td>70529.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12020 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          SEQN  RIDAGEYR  RIAGENDR  RIDRETH1  BPXSY1  BMXBMI  SMQ020  LBXTC  \\\n",
       "0      47698.0      55.0       1.0       2.0   130.0    27.8     1.0  176.0   \n",
       "1      68073.0      58.0       1.0       4.0   120.0    26.6     1.0  112.0   \n",
       "2      77090.0      43.0       2.0       4.0   138.0    29.7     2.0    NaN   \n",
       "3      43558.0      69.0       1.0       3.0   186.0    24.1     1.0  138.0   \n",
       "4      59274.0      68.0       2.0       1.0   144.0    26.6     1.0  237.0   \n",
       "...        ...       ...       ...       ...     ...     ...     ...    ...   \n",
       "12015  77674.0      55.0       2.0       4.0   116.0    22.2     1.0  226.0   \n",
       "12016  74600.0      66.0       2.0       4.0   144.0    35.1     1.0  200.0   \n",
       "12017  66287.0      47.0       1.0       5.0   116.0    24.7     1.0  232.0   \n",
       "12018  76281.0      49.0       2.0       3.0   136.0    15.2     1.0  207.0   \n",
       "12019  70529.0      49.0       1.0       3.0     NaN    27.8     1.0  171.0   \n",
       "\n",
       "       PAD615  ALQ101  DIQ010  status  \n",
       "0         NaN     1.0     2.0       0  \n",
       "1         NaN     1.0     1.0       0  \n",
       "2         NaN     NaN     1.0       0  \n",
       "3         NaN     1.0     1.0       1  \n",
       "4         NaN     1.0     1.0       0  \n",
       "...       ...     ...     ...     ...  \n",
       "12015     NaN     1.0     2.0       1  \n",
       "12016     NaN     1.0     2.0       1  \n",
       "12017     NaN     1.0     2.0       0  \n",
       "12018     NaN     1.0     2.0       1  \n",
       "12019     NaN     1.0     2.0       1  \n",
       "\n",
       "[12020 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clean the data & process the missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SEQN        0.000000\n",
       "RIDAGEYR    0.000000\n",
       "RIAGENDR    0.000000\n",
       "RIDRETH1    0.000000\n",
       "BPXSY1      0.082862\n",
       "BMXBMI      0.017055\n",
       "SMQ020      0.000000\n",
       "LBXTC       0.059983\n",
       "PAD615      0.849334\n",
       "ALQ101      0.095258\n",
       "DIQ010      0.000000\n",
       "status      0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# glipse the peoportion\n",
    "proportion = df_train.isnull().sum(axis=0)/df_train.shape[0]\n",
    "proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'BPXDI1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-edd72ee04ac3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBMXBMI\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'BMXBMI'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBMXBMI\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLBXTC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'LBXTC'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLBXTC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBPXDI1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'BPXDI1'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBPXDI1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPAD615\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'PAD615'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPAD615\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5272\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5273\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5274\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5276\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'BPXDI1'"
     ]
    }
   ],
   "source": [
    "# continous numeirical data in train set\n",
    "df_train.loc[df_train.RIDAGEYR.isnull(), 'RIDAGEYR'] = df_train.RIDAGEYR.mean()\n",
    "df_train.loc[df_train.BPXSY1.isnull(), 'BPXSY1'] = df_train.BPXSY1.mean()\n",
    "df_train.loc[df_train.BMXBMI.isnull(), 'BMXBMI'] = df_train.BMXBMI.mean()\n",
    "df_train.loc[df_train.LBXTC.isnull(), 'LBXTC'] = df_train.LBXTC.mean()\n",
    "df_train.loc[df_train.BPXDI1.isnull(), 'BPXDI1'] = df_train.BPXDI1.mean()\n",
    "df_train.loc[df_train.PAD615.isnull(), 'PAD615'] = df_train.PAD615.mean()\n",
    "\n",
    "# continous numeirical data in test set\n",
    "df_test.loc[df_test.RIDAGEYR.isnull(), 'RIDAGEYR'] = df_test.RIDAGEYR.mean()\n",
    "df_test.loc[df_test.BPXSY1.isnull(), 'BPXSY1'] = df_test.BPXSY1.mean()\n",
    "df_test.loc[df_test.BMXBMI.isnull(), 'BMXBMI'] = df_test.BMXBMI.mean()\n",
    "df_test.loc[df_test.LBXTC.isnull(), 'LBXTC'] = df_test.LBXTC.mean()\n",
    "df_test.loc[df_test.BPXDI1.isnull(), 'BPXDI1'] = df_test.BPXDI1.mean()\n",
    "df_test.loc[df_test.PAD615.isnull(), 'PAD615'] = df_test.PAD615.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean ALQ101\n",
    "df_train.dropna(axis = 0, how = 'any', inplace = True)\n",
    "df_test.dropna(axis = 0, how = 'any', inplace = True)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.isnull().sum(axis=0)\n",
    "df_test.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALQ101  7refused\n",
    "# SMQ020  7refused\n",
    "# DIQ010  7refused\n",
    "df_train.drop(df_train[df_train.SMQ020 == 7].index)\n",
    "df_train.drop(df_train[df_train.DIQ010 == 7].index)\n",
    "df_train.drop(df_train[df_train.ALQ101 == 7].index)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_feature = df_train.drop(['SEQN'], axis = 1)\\\n",
    "                       .drop(['RIAGENDR'], axis = 1)\\\n",
    "                       .drop(['RIDRETH1'], axis = 1)\\\n",
    "                       .drop(['SMQ020'], axis = 1)\\\n",
    "                       .drop(['DIQ010'], axis = 1)\\\n",
    "                       .drop(['ALQ101'], axis = 1)\\\n",
    "                       .drop(['status'], axis = 1)\n",
    "data_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "df = pd.DataFrame(data_feature)\n",
    "pairplot_fig = sns.pairplot(df)\n",
    "pairplot_fig.savefig('pairplot1.png',dpi = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_cor = data_feature.drop(['PAD615'], axis = 1)\n",
    "data_for_cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age = data_for_cor.RIDAGEYR.values\n",
    "\n",
    "cor_list = []\n",
    "# for i in range(data_feature.shape[1]-1):\n",
    "cor_1 = np.corrcoef(data_for_cor.BPXSY1.values, age)\n",
    "cor_list.append(abs(cor_1[0,1]))\n",
    "cor_2 = np.corrcoef(data_for_cor.BPXDI1.values, age)\n",
    "cor_list.append(abs(cor_2[0,1]))\n",
    "cor_3 = np.corrcoef(data_for_cor.BMXBMI.values, age)\n",
    "cor_list.append(abs(cor_3[0,1]))\n",
    "cor_4 = np.corrcoef(data_for_cor.LBXTC.values, age)\n",
    "cor_list.append(abs(cor_4[0,1]))\n",
    "print(cor_list)\n",
    "plt.plot(range(len(cor_list)),cor_list, c='y')\n",
    "plt.bar(range(len(cor_list)),cor_list, width = 0.5)\n",
    "plt.ylabel('cor')\n",
    "plt.title('correlation between features')\n",
    "plt.ylim([0,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## label the catogorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [\"RIAGENDR\", \"SMQ020\", \"RIDRETH1\", \"DIQ010\", \"ALQ101\"]\n",
    "other_cols = [\"RIDAGEYR\", \"BPXSY1\",\"BPXDI1\", \"BMXBMI\", \"LBXTC\", \"PAD615\"]\n",
    "\n",
    "list = [df_train[other_cols]]\n",
    "\n",
    "for i in cat_cols:\n",
    "    df_train = pd.get_dummies(df_train, prefix=[i], columns = [i], drop_first=True)\n",
    "\n",
    "y_train = df_train.status\n",
    "X_train = df_train.drop(['status'], axis=1)\n",
    "# X_train = X_train.drop(['BPXCHR'],axis = 1)\n",
    "X_train = X_train.drop(['SEQN'],axis = 1)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cat_cols:\n",
    "    df_test = pd.get_dummies(df_test, prefix=[i], columns = [i], drop_first=True)\n",
    "\n",
    "y_test  = df_test.status\n",
    "X_test = df_test.drop(['status'], axis=1)\n",
    "# X_test = X_test.drop(['BPXCHR'], axis = 1)\n",
    "X_test = X_test.drop(['SEQN'], axis = 1)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the first method to match in 'model establishment and measurement' part of dissertation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols = X_train.columns\n",
    "for col in train_cols:\n",
    "    if col not in X_test:\n",
    "        X_test.loc[:,col] = 0\n",
    "        \n",
    "# match columns\n",
    "X_test = X_test[train_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the second method to match in 'contrast of models and exploration of the reason behind' part of dessertation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_cols = X_train.columns\n",
    "# for col in train_cols:\n",
    "#     if col not in X_test:\n",
    "#         X_train = X_train.drop([col], axis=1)\n",
    "# X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## establish and assess models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "#use the model\n",
    "rf = RandomForestClassifier() \n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "rf_predicted = rf.predict(X_test)\n",
    "\n",
    "#print the score\n",
    "print(\"training set score:{:.3f}\".format(rf.score(X_train, y_train))) \n",
    "print(\"test set score:{:.3f}\".format(rf.score(X_test,y_test)))\n",
    "\n",
    "#print the confusion matrix\n",
    "confusion_matrix(y_test, rf_predicted) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_roc_curve(predicted, y_test)\n",
    "metrics.plot_roc_curve(rf, X_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "lr_predicted = lr.predict(X_test)\n",
    "\n",
    "print(lr.coef_, lr.intercept_)\n",
    "\n",
    "#print the score\n",
    "print(\"training set score:{:.3f}\".format(lr.score(X_train, y_train))) \n",
    "print(\"test set score:{:.3f}\".format(lr.score(X_test,y_test)))\n",
    "\n",
    "#print the confusion matrix\n",
    "confusion_matrix(y_test, lr_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.plot_roc_curve(lr, X_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "knn_predicted = knn.predict(X_test)\n",
    "\n",
    "#print the score\n",
    "print(\"training set score:{:.3f}\".format(knn.score(X_train, y_train))) \n",
    "print(\"test set score:{:.3f}\".format(knn.score(X_test,y_test)))\n",
    "\n",
    "#print the confusion matrix\n",
    "confusion_matrix(y_test, knn_predicted) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.plot_roc_curve(knn, X_test, y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rocs_plot(y_test_list, y_pred_list, setname=''):\n",
    "#     plt.figure(figsize = (5,4), dpi = 100)\n",
    "    plt.style.use('seaborn-darkgrid')\n",
    "    \n",
    "    for i, y_pred in enumerate(y_pred_list):\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_test_list[i], y_pred)\n",
    "        roc_auc = metrics.auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, lw = 1, label = \"AUC = %0.3f\" % roc_auc)\n",
    "    plt.xlim([0,1])\n",
    "    plt.ylim([0,1])\n",
    "#     plt.axis('equal')\n",
    "    plt.xlabel('false prositive rate(fpr)')\n",
    "    plt.ylabel('true prositive rate(tpr)')\n",
    "    plt.title('ROC Curves')\n",
    "    \n",
    "y_test_list = [y_test, y_test, y_test]\n",
    "y_pred_list = [rf_predicted, lr_predicted, knn_predicted]\n",
    "rocs_plot(y_test_list, y_pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "import matplotlib.lines as mlines\n",
    "prob_true, prob_pred = calibration_curve(y_test, lr_predicted, n_bins = 50)\n",
    "\n",
    "plt.plot(prob_pred, prob_true)\n",
    "plt.plot([0,1],[0,1], c = 'r', linestyle = 'dashed')\n",
    "plt.xlim([-0.05,1.05])\n",
    "plt.ylim([-0.05,1.05])\n",
    "plt.xlabel('probabilty prediction')\n",
    "plt.ylabel('probabilty true')\n",
    "plt.title('calibration curve -- logistic regression')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_true_1, prob_pred_1 = calibration_curve(y_test, rf_predicted, n_bins = 50)\n",
    "\n",
    "plt.plot(prob_pred_1, prob_true_1)\n",
    "plt.plot([0,1],[0,1], c = 'r', linestyle = 'dashed')\n",
    "plt.xlim([-0.05,1.05])\n",
    "plt.ylim([-0.05,1.05])\n",
    "plt.xlabel('probabilty prediction')\n",
    "plt.ylabel('probabilty true')\n",
    "plt.title('calibration curve -- random forest')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optimize the hyperparameters & check the overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "rf_train_score = []\n",
    "rf_test_score = []\n",
    "for i in range(2, 9):\n",
    "    rf_model = RandomForestClassifier(max_depth = i)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    rf_train_pred = rf_model.predict(X_train)\n",
    "    train_acc = accuracy_score(y_train, rf_train_pred)\n",
    "    rf_train_score.append(train_acc)\n",
    "    \n",
    "    rf_test_pred = rf_model.predict(X_test)\n",
    "    test_acc = accuracy_score(y_test, rf_test_pred)\n",
    "    rf_test_score.append(test_acc)\n",
    "    \n",
    "plt.plot(range(2, 9), rf_train_score, marker = 'o', label='random forset train R2')\n",
    "plt.plot(range(2, 9), rf_test_score, marker = '*', label='random forest test R2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_train_auc = []\n",
    "rf_test_auc = []\n",
    "for i in range(2, 9):\n",
    "    rf_model = RandomForestClassifier(max_depth = i)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    rf_train_pred = rf_model.predict(X_train)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_train, rf_train_pred)\n",
    "    roc_auc_train = metrics.auc(fpr, tpr)\n",
    "    rf_train_auc.append(roc_auc_train)\n",
    "    \n",
    "    rf_test_pred = rf_model.predict(X_test)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, rf_test_pred)\n",
    "    roc_auc_test = metrics.auc(fpr, tpr)\n",
    "    rf_test_auc.append(roc_auc_test)\n",
    "    \n",
    "plt.plot(range(2, 9), rf_train_auc, marker = 'o', label='random forest train AUC')\n",
    "plt.plot(range(2, 9), rf_test_auc, marker = '*', label='random forest test AUC')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_train_score = []\n",
    "knn_test_score = []\n",
    "for i in range(2,10):\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn_model.fit(X_train, y_train)\n",
    "    knn_train_pred = knn_model.predict(X_train)\n",
    "    train_acc = accuracy_score(y_train, knn_train_pred)\n",
    "    knn_train_score.append(train_acc)\n",
    "    \n",
    "    knn_test_pred = knn_model.predict(X_test)\n",
    "    test_acc = accuracy_score(y_test, knn_test_pred)\n",
    "    knn_test_score.append(test_acc)\n",
    "    \n",
    "plt.plot(range(2,10), knn_train_score, marker = 'o', label='knn train R2')\n",
    "plt.plot(range(2,10), knn_test_score, marker = '*', label='knn test R2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_train_auc = []\n",
    "knn_test_auc = []\n",
    "for i in range(2, 9):\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn_model.fit(X_train, y_train)\n",
    "    knn_train_pred = knn_model.predict(X_train)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_train, knn_train_pred)\n",
    "    roc_auc_train = metrics.auc(fpr, tpr)\n",
    "    knn_train_auc.append(roc_auc_train)\n",
    "    \n",
    "    knn_test_pred = knn_model.predict(X_test)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, knn_test_pred)\n",
    "    roc_auc_test = metrics.auc(fpr, tpr)\n",
    "    knn_test_auc.append(roc_auc_test)\n",
    "    \n",
    "plt.plot(range(2, 9), knn_train_auc, marker = 'o', label='knn train AUC')\n",
    "plt.plot(range(2, 9), knn_test_auc, marker = '*', label='knn test AUC')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## random forest: optimization without package (not very important)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample(data_set, n):\n",
    "    rows = np.random.choice(len(data_set), n)\n",
    "    tr = data_set.iloc[rows]\n",
    "    x_tr = tr.iloc[:, 0: tr.shape[1] - 1]\n",
    "    y_tr = tr.iloc[:, tr.shape[1] - 1]\n",
    "    return x_tr, y_tr\n",
    "\n",
    "def regErr(data_set):\n",
    "    return np.var(data_set[:,-1])*shape(data_set)[0]\n",
    "\n",
    "def regLeaf(data_set):\n",
    "    return np.mean(data_set[:,-1])\n",
    "\n",
    "\n",
    "def find_split(x, y):\n",
    "    best = {'infogain' : np.inf}\n",
    "    for i in range(x.shape[1]):\n",
    "        for split in np.unique(x.iloc[:,i]):\n",
    "            indices = np.arange(x.shape[0])\n",
    "            going_left = x.iloc[indices, i] <= split\n",
    "            left_indices = indices[going_left]\n",
    "            right_indices = indices[np.logical_not(going_left)]\n",
    "            \n",
    "            infogain = np.var(y.iloc[left_indices]) * len(left_indices) + np.var(y.iloc[right_indices]) * len(right_indices)\n",
    "                                                                                            \n",
    "            if infogain < best['infogain']:\n",
    "                best = {'feature' : i,\n",
    "                        'split' : split,\n",
    "                        'infogain' : infogain, \n",
    "                        'left_indices' : left_indices,\n",
    "                        'right_indices' : right_indices}\n",
    "    return best\n",
    "\n",
    "def gini(data_set):\n",
    "    corr=0.0\n",
    "    for i in set(data_set[:,-1]):\n",
    "        corr += (len(np.nonzero(data_set[:,-1]==i)[0])/len(data_set))**2\n",
    "    return 1-corr\n",
    "\n",
    "def build_tree(x, y, max_depth):\n",
    "    if max_depth == 1 or (y==y.iloc[0]).all():\n",
    "        return {'leaf' : True, 'prediction' : y.mean()}\n",
    "        \n",
    "    else:\n",
    "        move = find_split(x, y)\n",
    "        \n",
    "        left = build_tree(x.iloc[move['left_indices'],:], y.iloc[move['left_indices']], max_depth - 1)\n",
    "        right = build_tree(x.iloc[move['right_indices'],:], y.iloc[move['right_indices']], max_depth - 1)\n",
    "        \n",
    "        return {'leaf' : False,\n",
    "                'feature' : move['feature'],\n",
    "                'split' : move['split'],\n",
    "                'infogain' : move['infogain'],\n",
    "                'left' : left,\n",
    "                'right' : right}\n",
    "    \n",
    "    \n",
    "def predict(tree, samples):\n",
    "    ret = np.empty(samples.shape[0], dtype=float)\n",
    "    ret.fill(0.0)\n",
    "    indices = np.arange(samples.shape[0])\n",
    "    \n",
    "    def tranverse(node, indices):\n",
    "        nonlocal samples\n",
    "        nonlocal ret\n",
    "        \n",
    "        if node['leaf']:\n",
    "            ret[indices] = node['prediction']\n",
    "        \n",
    "        else:\n",
    "            going_left = samples.iloc[indices, node['feature']] <= node['split']\n",
    "            left_indices = indices[going_left]\n",
    "            right_indices = indices[np.logical_not(going_left)]\n",
    "            \n",
    "            if left_indices.shape[0] > 0:\n",
    "                tranverse(node['left'], left_indices)\n",
    "                \n",
    "            if right_indices.shape[0] > 0:\n",
    "                tranverse(node['right'], right_indices)\n",
    "    \n",
    "    tranverse(tree, indices)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_for = []\n",
    "X_tree = pd.concat([X_train, y_train],axis=1)\n",
    "\n",
    "for i in range(7):\n",
    "    x_tr, y_tr = get_sample(X_tree,500)\n",
    "    tree_single = build_tree(x_tr, y_tr, 5)\n",
    "    tree_for.append(tree_single)\n",
    "        \n",
    "pred_m = np.zeros(shape = (len(tree_for), len(y_test)))\n",
    "for i in range(len(tree_for)):\n",
    "    prediction = predict(tree_for[i], X_test)\n",
    "    pred_m[i, :] = prediction\n",
    "prediction_rfr = np.mean(pred_m, axis = 0)\n",
    "# score(prediction_rfr, np.array(y_test))\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, prediction_rfr)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "print(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(pred_y, true_y):\n",
    "    MSE = np.sum(np.power(pred_y - true_y,2)) / len(pred_y)\n",
    "    RMSE = np.sqrt(MSE)\n",
    "#     R2 = 1 - MSE / np.var(true_y)\n",
    "    R2 = 1 - np.sum(np.power(pred_y - true_y,2)) / np.sum(np.power(true_y - np.mean(true_y),2))\n",
    "    return R2\n",
    "\n",
    "def draw_img(k, auc):\n",
    "#     plt.figure(figsize = (15, 7))\n",
    "    plt.ylabel('auc')\n",
    "    plt.xlabel(\"hypermeter\")\n",
    "    plt.plot(k, auc)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_lis = []\n",
    "tree_number_lis = []\n",
    "tree_for = []\n",
    "for number in range(2,9):\n",
    "    for i in range(number):\n",
    "        x_tr, y_tr = get_sample(X_tree, 500)\n",
    "        tree_single = build_tree(x_tr, y_tr, 5)\n",
    "        tree_for.append(tree_single)\n",
    "        \n",
    "    pred_m = np.zeros(shape = (len(tree_for), len(y_test)))\n",
    "    for i in range(len(tree_for)):\n",
    "        prediction = predict(tree_for[i], X_test)\n",
    "        pred_m[i, :] = prediction\n",
    "    prediction_rfr = np.mean(pred_m, axis = 0)\n",
    "\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, prediction_rfr)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    auc_lis.append(roc_auc)\n",
    "    tree_number_lis.append(number)\n",
    "    print(number,roc_auc)\n",
    "    \n",
    "draw_img(tree_number_lis, auc_lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
